{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio V.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcestevezc/Machine-Learning-Techniques/blob/master/Laboratorio%205/Laboratorio_V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ffxRZZbhIP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://cursos.virtual.uniandes.edu.co/isis4219/wp-content/uploads/sites/162/2014/11/cropped-misisheader.png\" ><br>\n",
        "# Machine Learning Techniques - ISIS4219\n",
        "\n",
        "Intersemestral 2020\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j79las3xZgA1",
        "colab_type": "text"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "*   Analizar la estructura de una Red Neuronal.\n",
        "*   Construir un modelo a través de `Keras` y `TensorFlow`.\n",
        "*   Realizar la búsqueda de hiperparámetros para ajustar una Red Neuronal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsHx_hJ6ZECS",
        "colab_type": "text"
      },
      "source": [
        "## Primer Problema\n",
        "<p style=\"text-align: justify;\"> El departamento de TI ha desarrollado un servidor de correo para brindar a todos los empleados una cuenta propia donde puedan manejar la información de la empresa. Sin embargo, debido al mal manejo de la cuenta y la falta de capacitación, los directivos se han dado cuenta que a los servidores están llegando varios mensajes <i>Spam</i> que pueden comprometer la seguridad de la información. Para eso, les han pedido construir un sistema el cual permita clasificar y descartar un mensaje <i>Spam</i> antes que llegue a los servidores. \n",
        "\n",
        "<br> Debido a que es un problema reciente y los directivos quieren actuar rápido le han brindado el siguiente archivo con los datos que lograron etiquetar, y les sugieren que utilicen un ***MLP***, ya que han escuchado que son muy buenos.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSTJi8iWcTAB",
        "colab_type": "text"
      },
      "source": [
        "### 1. Importando las librerias requeridas para el desarrollo del laboratorio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAdksbLPQEcC",
        "colab_type": "text"
      },
      "source": [
        "Para la transformación de los datos, así como para el entrenamiento de los modelos y la visualización de los resultados, se importan las siguientes librerías:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rINYNqq66Qi",
        "colab_type": "text"
      },
      "source": [
        "**Nota:** Para asegurarse de tener las últimas versiones y todos los paquetes instalados que por lo general no vienen en Google Colab. pueden ejecutar la sigiuente celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRUFJel57RaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e1fcc6e5-4cbc-44c9-9fef-d4f05b2fbfa1"
      },
      "source": [
        "!pip install contractions\n",
        "import nltk\n",
        "#nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ScRe1oQoS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fcbfd915-4373-414e-f22f-6d3922ce2b35"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "import re, string, unicodedata\n",
        "import contractions\n",
        "import inflect\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, make_scorer\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "print('Tensorflow version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPg_tCo9q-Y1",
        "colab_type": "text"
      },
      "source": [
        "### 2. Perfilamiento y entendimiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzd4WpEc0wH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "#### Lectura de los datos\n",
        "Primero, se leen los datos y se visualizan que se hayan leido correctamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSOQmVQwJON7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f946eb95-3a97-4e63-df1f-4e362fe0e0eb"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/jcestevezc/Machine-Learning-Techniques/master/Laboratorio%205/Punto%201/SPAM%20text%20message%2020170820%20-%20Data.csv'\n",
        "data = pd.read_csv(url)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xctGhNVcs3Z",
        "colab_type": "text"
      },
      "source": [
        "### 3. Preparación de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SJ-GOnjZbHt",
        "colab_type": "text"
      },
      "source": [
        "Para poder realizar el pre-procesamiento de los datos, es recomendable pasar por tres etapas:\n",
        "* Eliminación del Ruido.\n",
        "* Tokenización.\n",
        "* Normalización.\n",
        "\n",
        "Para mayor información, pueden consultar el [siguiente artículo](https://medium.com/datos-y-ciencia/preprocesamiento-de-datos-de-texto-un-tutorial-en-python-5db5620f1767\n",
        ")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeKFwj3cdHnx",
        "colab_type": "text"
      },
      "source": [
        "#### **3.1 Eliminación del Ruido**\n",
        "La eliminación del ruido se utiliza para dejar el archivo en texto plano, sobre todo cuando vienen de diferentes fuentes como HTML, Twitter, XML, entre otros. También para eliminar caracteres especiales y pasar todo a minúscula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMVA9gOc87WY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def preproccesing(words):\n",
        "    words = to_lowercase(words)\n",
        "    words = replace_numbers(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = remove_non_ascii(words)\n",
        "    words = remove_stopwords(words)\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJqG_OevdhCP",
        "colab_type": "text"
      },
      "source": [
        "#### **3.2 Tokenización**\n",
        "La tokenización permite dividir frases u oraciones en palabras. Con el fin de desglozar las palabras correctamente para el posterior análisis. Pero primero, se realiza una corrección de las contracciones que pueden estar presentes en los textos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpCOR728Aurq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Message'] = data['Message'].apply(contractions.fix) #Aplica la corrección de las contracciones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vq20mVKf9KY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "af7c4433-d717-485d-a96c-5beaebada10b"
      },
      "source": [
        "data['words'] = data['Message'].apply(word_tokenize)\n",
        "data['words'] = data['words'].apply(preproccesing) #Aplica la eliminación del ruido\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[ok, lar, joking, wif, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[free, entry, two, wkly, comp, win, fa, cup, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[dun, say, early, hor, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category  ...                                              words\n",
              "0      ham  ...  [go, jurong, point, crazy, available, bugis, n...\n",
              "1      ham  ...                        [ok, lar, joking, wif, oni]\n",
              "2     spam  ...  [free, entry, two, wkly, comp, win, fa, cup, f...\n",
              "3      ham  ...            [dun, say, early, hor, c, already, say]\n",
              "4      ham  ...     [nah, think, goes, usf, lives, around, though]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTMPaRyDF449",
        "colab_type": "text"
      },
      "source": [
        "#### **Normalización**\n",
        "Para la normalización de los datos se realiza una eliminación de prefijos y sufijos, además de realizar una lemmatización de los verbos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwdBwMV5gpqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "299f6753-59ec-42cb-8a08-045492f4f4ba"
      },
      "source": [
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def stem_and_lemmatize(words):\n",
        "    stems = stem_words(words)\n",
        "    lemmas = lemmatize_verbs(words)\n",
        "    return stems + lemmas\n",
        "\n",
        "data['words'] = data['words'].apply(stem_and_lemmatize) #Aplica lematización y Eliminación de Prefijos y Sufijos.\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[go, jurong, point, crazy, avail, bug, n, gre,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[ok, lar, jok, wif, on, ok, lar, joke, wif, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[fre, entry, two, wkly, comp, win, fa, cup, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[dun, say, ear, hor, c, already, say, dun, say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[nah, think, goe, usf, liv, around, though, na...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category  ...                                              words\n",
              "0      ham  ...  [go, jurong, point, crazy, avail, bug, n, gre,...\n",
              "1      ham  ...   [ok, lar, jok, wif, on, ok, lar, joke, wif, oni]\n",
              "2     spam  ...  [fre, entry, two, wkly, comp, win, fa, cup, fi...\n",
              "3      ham  ...  [dun, say, ear, hor, c, already, say, dun, say...\n",
              "4      ham  ...  [nah, think, goe, usf, liv, around, though, na...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkioZkNn9hiE",
        "colab_type": "text"
      },
      "source": [
        "##### **3.4 Selección de campos**\n",
        "\n",
        "Primero, se separa la variable predictora y los textos que se van a utilizar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1JC3_G5lJim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ce841722-8d19-4b44-b9ba-1f25a1e21e7f"
      },
      "source": [
        "data['words'] = data['words'].apply(lambda x: ' '.join(map(str, x)))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go jurong point crazy avail bug n gre world la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>ok lar jok wif on ok lar joke wif oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>fre entry two wkly comp win fa cup fin tkts 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>dun say ear hor c already say dun say early ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>nah think goe usf liv around though nah think ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact y...</td>\n",
              "      <td>2nd tim tri two contact 750 pound priz two cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "      <td>u b going esplanad fr hom u b go esplanade fr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity mood suggest pity mood suggestions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like I w...</td>\n",
              "      <td>guy bitch act lik would interest buy someth el...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl tru nam rofl true name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                              words\n",
              "0         ham  ...  go jurong point crazy avail bug n gre world la...\n",
              "1         ham  ...              ok lar jok wif on ok lar joke wif oni\n",
              "2        spam  ...  fre entry two wkly comp win fa cup fin tkts 21...\n",
              "3         ham  ...  dun say ear hor c already say dun say early ho...\n",
              "4         ham  ...  nah think goe usf liv around though nah think ...\n",
              "...       ...  ...                                                ...\n",
              "5567     spam  ...  2nd tim tri two contact 750 pound priz two cla...\n",
              "5568      ham  ...  u b going esplanad fr hom u b go esplanade fr ...\n",
              "5569      ham  ...            pity mood suggest pity mood suggestions\n",
              "5570      ham  ...  guy bitch act lik would interest buy someth el...\n",
              "5571      ham  ...                        rofl tru nam rofl true name\n",
              "\n",
              "[5572 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5IOKin8OMWn",
        "colab_type": "text"
      },
      "source": [
        "Ya con los textos preprocesados, se obtiene una transformación de la variable predictora. En este caso no se hará una categorización binaria sino que se obtendrán los valores dummies, con el fin de demostrar que una red no necesariamente puede tener una sola salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79hYV9-w-d-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bbf22bad-ce9a-43b4-dd6b-c15a9b692ff9"
      },
      "source": [
        "X, y = data['words'],data['Category']\n",
        "y = pd.get_dummies(y)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ham</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ham  spam\n",
              "0       1     0\n",
              "1       1     0\n",
              "2       0     1\n",
              "3       1     0\n",
              "4       1     0\n",
              "...   ...   ...\n",
              "5567    0     1\n",
              "5568    1     0\n",
              "5569    1     0\n",
              "5570    1     0\n",
              "5571    1     0\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zspxAgCl3Vsc",
        "colab_type": "text"
      },
      "source": [
        "Y con los textos obtenidos, se realiza la transformación Term-frecuency times inverse Document-frecuency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHytuAYWAeiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5a2a13a7-a6a2-4035-dbba-b66c68a8c174"
      },
      "source": [
        "tf_idf = TfidfVectorizer()\n",
        "X_tf_idf = tf_idf.fit_transform(X)\n",
        "print(X_tf_idf.shape)\n",
        "X_tf_idf.toarray()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 10047)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCPvB6qNdAUo",
        "colab_type": "text"
      },
      "source": [
        "### 4. Modelamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtEJHm4lKG3t",
        "colab_type": "text"
      },
      "source": [
        "#### 4.1 Arquitectura\n",
        "\n",
        "Para el desarrollo del laboratorio se utilizará una arquitectura Multilayer Perceptron estructurada de la siguiente manera:\n",
        "\n",
        "![Multilayer Perceptron](https://github.com/jcestevezc/Machine-Learning-Techniques/blob/master/Laboratorio%205/MLP.png?raw=true)\n",
        "\n",
        "Para conocer un poco mas acerca de los diferentes tipos de arquitecturas, pueden encontrar mas información en el siguiente enlace: [Arquitecturas](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGe28y8mPI7L",
        "colab_type": "text"
      },
      "source": [
        "Siempre para las Redes Neuronales, es importante especificar la dimensión de entrada y la dimensión de la salida esperada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc4wLuK6eHvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = (X_tf_idf.shape)[1]\n",
        "output = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7385-i8LQXln",
        "colab_type": "text"
      },
      "source": [
        "Primero, definimos nuestro conjunto de entrenamiento y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRnd7TUTnnLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tf_idf.toarray(), y.values, test_size=0.2, random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP59wUN9IQIw",
        "colab_type": "text"
      },
      "source": [
        "**Tipos de Layers**\n",
        "\n",
        "Para este ejercicio en particular se utilizarán las ***Core layers*** de Keras:\n",
        "\n",
        "*   **Input object**\n",
        "*   **Dense layer**\n",
        "*   **Activation layer**\n",
        "*   Embedding layer\n",
        "*   Masking layer\n",
        "*   Lambda layer\n",
        "\n",
        "Regularization layers:\n",
        "\n",
        "*   **Dropout layer**\n",
        "*   SpatialDropout1D layer\n",
        "*   SpatialDropout2D layer\n",
        "*   SpatialDropout3D layer\n",
        "*   GaussianDropout layer\n",
        "*   GaussianNoise layer\n",
        "*   ActivityRegularization layer\n",
        "*   AlphaDropout layer\n",
        "\n",
        "Para conocer mas en detalle los diferentes tipo de capas, se pueden consultar en el siguiente enlace: [Keras Layers](https://keras.io/api/layers/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiwOt2hlPuln",
        "colab_type": "text"
      },
      "source": [
        "Y así de fácil se puede construir un modelo con `Keras`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqjaU7nWgo77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se inicializa el modelo\n",
        "model = Sequential()\n",
        "#Se agrega la primera capa\n",
        "model.add(Dense(512, input_dim = input))\n",
        "#Se define su función de activación\n",
        "model.add(Activation('relu'))\n",
        "#Se define la tasa de Dropout\n",
        "model.add(Dropout(0.5))\n",
        "#Se define la capa de salida\n",
        "model.add(Dense(2))\n",
        "#Se define la función de activación\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ShuGWdtguFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7ae7718d-eb96-4f5d-8921-e146fa110d81"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               5144576   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 5,145,602\n",
            "Trainable params: 5,145,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze9cmPhkSQCg",
        "colab_type": "text"
      },
      "source": [
        "Algunas de las decisiones a tomar durante el proceso de construcción de la red son la selección de:\n",
        "1. La función de [perdida](https://keras.io/api/losses/):\n",
        "\n",
        "\n",
        "> * binary_crossentropy function\n",
        "> * categorical_crossentropy function\n",
        "> * ...\n",
        "\n",
        "2. El [optimizador](https://medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6#:~:text=Optimizers%20are%20algorithms%20or%20methods,order%20to%20reduce%20the%20losses.&text=Optimization%20algorithms%20or%20strategies%20are,the%20most%20accurate%20results%20possible.) en [keras](https://keras.io/api/optimizers/):\n",
        "\n",
        "> * SGD\n",
        "> * Adam\n",
        "> * ...\n",
        "\n",
        "3. Las metricas de [evaluación](https://keras.io/api/metrics/):\n",
        "\n",
        "> * Accuracy metrics\n",
        "> * Probabilistic metrics\n",
        "> * Regression metrics\n",
        "> * Classification metrics based on True/False positives & negatives\n",
        "> * Image segmentation metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-d2ICI0QiwW",
        "colab_type": "text"
      },
      "source": [
        "Y se 'compila', para poder entrenar los parámetros del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpwqiTxhQidx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"SGD\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9MPah-RR2O1",
        "colab_type": "text"
      },
      "source": [
        "#### 4.2 Control de la complejidad y los tiempos de procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqqF0iZLL5j6",
        "colab_type": "text"
      },
      "source": [
        "Una forma de ***controlar la complejidad y los tiempos de procesamiento***, es mediante el uso de ***callbacks***. Los anteriores son acciones durante las etapas del entrenamiento. Por ejemplo: al comienzo o al final del epoch, antes o después de un solo lote, etc.\n",
        "\n",
        "Existen varios tipos de [callbacks](https://keras.io/api/callbacks/), sin embargo para este laboratorio se utilizará *EarlyStopping*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-_aC8ESLuTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
        "callbacks = [early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVUkOROeOKDb",
        "colab_type": "text"
      },
      "source": [
        "Algunos parametros importantes de EarlyStopping son:\n",
        "\n",
        "* **monitor**: permite especificar la metrica a ser monitoreada.\n",
        "\n",
        "* **patience**: corresponde al número de epochs maximo en que se continuará el entrenamiento a pesar de que no haya mejora.\n",
        "* **modo**: puede ser {\"auto\", \"min\", \"max\"}. En modo min, el entrenamiento se detendrá cuando la cantidad monitoreada haya dejado de disminuir; en modo \"max\" se detendrá cuando la cantidad monitoreada haya dejado de aumentar; en modo \"automático\", la dirección se infiere automáticamente del nombre de la cantidad monitoreada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7fBC4LnWmF5",
        "colab_type": "text"
      },
      "source": [
        "Algunas definiciones importantes:\n",
        "\n",
        "<img src=\"https://github.com/jcestevezc/Machine-Learning-Techniques/blob/master/Laboratorio%205/EpochBatch.jpeg?raw=true\" width=\"400\">\n",
        "\n",
        "**[Epoch](https://keras.io/getting_started/faq/#what-do-sample-batch-epoch-mean)**: generalmente definido como \"una pasada sobre todo el conjunto de datos\", utilizado para separar el entrenamiento en fases distintas, lo cual es útil para el registro y la evaluación periódica.\n",
        "\n",
        "**[Batch o lote](https://keras.io/getting_started/faq/#what-do-sample-batch-epoch-mean)**: un conjunto de N muestras. Las muestras en un lote se procesan de forma independiente, en paralelo. Si se está entrenando, un lote resulta en una sola actualización del modelo. Un lote generalmente se aproxima a la distribución de los datos de entrada mejor que una sola entrada. \n",
        "\n",
        "Cuanto más grande sea el lote, ***mejor será la aproximación***; sin embargo, también es cierto que el lote tardará más en procesarse y solo dará como resultado una actualización. \n",
        "\n",
        "Se recomienda elegir un tamaño de lote que sea tan grande como pueda permitirse sin quedarse sin memoria (ya que los lotes más grandes generalmente resultarán en una evaluación / predicción más rápida).\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/jcestevezc/Machine-Learning-Python/blob/master/Deep%20Learning/Batch%20Normalization%20Effects.PNG?raw=true\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqZwJ4HIWtnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "78296855-70bc-47fd-db86-8e90af0876f1"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs= 20, batch_size = 500, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 171ms/step - loss: 0.6821 - accuracy: 0.7097\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 2s 171ms/step - loss: 0.6493 - accuracy: 0.8665\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 2s 171ms/step - loss: 0.6200 - accuracy: 0.8667\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 2s 170ms/step - loss: 0.5935 - accuracy: 0.8667\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 2s 169ms/step - loss: 0.5701 - accuracy: 0.8667\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 2s 167ms/step - loss: 0.5485 - accuracy: 0.8667\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 3s 342ms/step - loss: 0.5293 - accuracy: 0.8667\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 165ms/step - loss: 0.5125 - accuracy: 0.8667\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 2s 169ms/step - loss: 0.4974 - accuracy: 0.8667\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 2s 167ms/step - loss: 0.4842 - accuracy: 0.8667\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 2s 170ms/step - loss: 0.4730 - accuracy: 0.8667\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 2s 170ms/step - loss: 0.4632 - accuracy: 0.8667\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 2s 167ms/step - loss: 0.4537 - accuracy: 0.8667\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 2s 168ms/step - loss: 0.4461 - accuracy: 0.8667\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 2s 170ms/step - loss: 0.4389 - accuracy: 0.8667\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 2s 173ms/step - loss: 0.4328 - accuracy: 0.8667\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 2s 168ms/step - loss: 0.4275 - accuracy: 0.8667\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 2s 171ms/step - loss: 0.4225 - accuracy: 0.8667\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 2s 169ms/step - loss: 0.4191 - accuracy: 0.8667\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 2s 167ms/step - loss: 0.4149 - accuracy: 0.8667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03zUwk4ohFDo",
        "colab_type": "text"
      },
      "source": [
        "Una simulación de las variables a tener en cuenta al momento de construir una red neuronal, la pueden encontrar en el siguiente playground de [tensorflow](http://playground.tensorflow.org/).\n",
        "\n",
        "![Playground](https://github.com/jcestevezc/Machine-Learning-Techniques/blob/master/Laboratorio%205/Playground.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS_0hWWIY8eQ",
        "colab_type": "text"
      },
      "source": [
        "Hay muchos hiperparámetros por entonar en el modelo, afortunadamente podemos seguir utilizando GridSearch. Sin embargo, no lo recomendamos debido a la gran cantidad de hiperparámetros que hay que entrenar. \n",
        "\n",
        "Para ello, construimos una función que nos permita construir la Red Neuronal esperada y utilizamos la función [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDz6zg8kzFGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entrenarRed(nn1 = 512, nn2 = 100, n_layers= 2, dropout = 0.1, activacion_oculta = 'relu'):\n",
        "    clf = Sequential(name='Mi_Red')\n",
        "    output = 2\n",
        "    first = True\n",
        "\n",
        "    for i in range(n_layers):\n",
        "        if first:\n",
        "            clf.add(Dense(nn1, activation=activacion_oculta, name='Capa_Entrada'))\n",
        "            first = False\n",
        "        else:\n",
        "            clf.add(Dense(nn2, activation=activacion_oculta, name = 'Capa_Oculta_{0}'.format(i)))\n",
        "    \n",
        "    clf.add(Dropout(dropout,name='Dropout_{0}'.format(dropout)))\n",
        "    clf.add(Dense(output, activation='sigmoid', name= 'Capa_Salida'))\n",
        "\n",
        "    clf.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "    \n",
        "    return clf\n",
        "\n",
        "# Modelo que utiliza el GridSearch\n",
        "modelCV = KerasClassifier(build_fn=entrenarRed, epochs=20, batch_size=20, verbose=1,shuffle = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuUMWWM0vGjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_custom_loss_func(y_true, y_pred):\n",
        "    return accuracy_score(y_true.argmax(axis=-1), y_pred)\n",
        "\n",
        "\n",
        "class toArray():\n",
        "    def __init__(self):\n",
        "        return\n",
        "\n",
        "    def transform(self, X, **transform_params):\n",
        "        return X.toarray()\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2JJFhaWZ9gr",
        "colab_type": "text"
      },
      "source": [
        "Con la función definida, se construye un pipeline para que el modelo solo tenga que recibir el texto que tiene que analizar, realice la transformación correspondiente y pueda realizar la clasificación con la mejor red encontrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSnKwF4F0PLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('transformacion',TfidfVectorizer()),\n",
        "                 ('matriz',toArray()),\n",
        "                  ('red_neuronal',modelCV)])\n",
        "\n",
        "param_grid = dict(transformacion=[TfidfVectorizer(),CountVectorizer()],\n",
        "                  red_neuronal__nn1 = [512, 10000, 100],\n",
        "                  red_neuronal__nn2 = [512, 10000, 100],\n",
        "                  red_neuronal__n_layers = [1,2],\n",
        "                  red_neuronal__dropout = [0.1,0.2,0.3],\n",
        "                  red_neuronal__activacion_oculta = ['relu','sigmoid']\n",
        "                  )\n",
        "\n",
        "score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
        "\n",
        "grid = RandomizedSearchCV(pipe, param_grid, scoring=score, verbose=1, cv = 3, n_iter=10, random_state=20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_lbadPEab6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa492ce3-9e03-47fc-db6b-f82d3388ccd8"
      },
      "source": [
        "Xtext_train, Xtext_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=33)\n",
        "\n",
        "grid.fit(Xtext_train, y_train,red_neuronal__callbacks=callbacks)\n",
        "\n",
        "best_model = grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "149/149 [==============================] - 31s 211ms/step - loss: 0.5028 - accuracy: 0.9101\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.3212 - accuracy: 0.9313\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2504 - accuracy: 0.9421\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.2125 - accuracy: 0.9522\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.1873 - accuracy: 0.9573\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 32s 217ms/step - loss: 0.1693 - accuracy: 0.9596\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.1544 - accuracy: 0.9616\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.1420 - accuracy: 0.9640\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.1311 - accuracy: 0.9657\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.1215 - accuracy: 0.9684\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.1120 - accuracy: 0.9680\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.1049 - accuracy: 0.9700\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 33s 220ms/step - loss: 0.0979 - accuracy: 0.9714\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.0906 - accuracy: 0.9724\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 33s 220ms/step - loss: 0.0845 - accuracy: 0.9754\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.0791 - accuracy: 0.9761\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.0736 - accuracy: 0.9785\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.0692 - accuracy: 0.9788\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 33s 222ms/step - loss: 0.0635 - accuracy: 0.9818\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.0598 - accuracy: 0.9842\n",
            "75/75 [==============================] - 6s 81ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.5120 - accuracy: 0.9004\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.3244 - accuracy: 0.9320\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.2493 - accuracy: 0.9445\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 31s 208ms/step - loss: 0.2076 - accuracy: 0.9559\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.1802 - accuracy: 0.9623\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.1613 - accuracy: 0.9643\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 31s 209ms/step - loss: 0.1468 - accuracy: 0.9667\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.1349 - accuracy: 0.9680\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.1241 - accuracy: 0.9687\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.1154 - accuracy: 0.9697\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 31s 206ms/step - loss: 0.1073 - accuracy: 0.9704\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.1006 - accuracy: 0.9721\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.0943 - accuracy: 0.9748\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.0883 - accuracy: 0.9761\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 31s 208ms/step - loss: 0.0834 - accuracy: 0.9778\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.0791 - accuracy: 0.9771\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 31s 206ms/step - loss: 0.0746 - accuracy: 0.9781\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.0707 - accuracy: 0.9795\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 31s 207ms/step - loss: 0.0667 - accuracy: 0.9818\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.0633 - accuracy: 0.9828\n",
            "75/75 [==============================] - 6s 80ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.5033 - accuracy: 0.9031\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.3166 - accuracy: 0.9344\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.2458 - accuracy: 0.9431\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.2091 - accuracy: 0.9502\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.1842 - accuracy: 0.9556\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.1673 - accuracy: 0.9606\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.1532 - accuracy: 0.9623\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.1421 - accuracy: 0.9637\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.1318 - accuracy: 0.9653\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.1238 - accuracy: 0.9664\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.1156 - accuracy: 0.9684\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.1080 - accuracy: 0.9684\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.1016 - accuracy: 0.9704\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.0953 - accuracy: 0.9717\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.0895 - accuracy: 0.9731\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.0834 - accuracy: 0.9754\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 32s 217ms/step - loss: 0.0788 - accuracy: 0.9758\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.0744 - accuracy: 0.9771\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.0710 - accuracy: 0.9795\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.0665 - accuracy: 0.9798\n",
            "75/75 [==============================] - 6s 83ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.4680 - accuracy: 0.8593\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.3894 - accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.3444 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.3173 - accuracy: 0.8650\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.3139 - accuracy: 0.8664\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.2899 - accuracy: 0.8667\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.2784 - accuracy: 0.8701\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.2688 - accuracy: 0.8734\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2587 - accuracy: 0.8731\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.2493 - accuracy: 0.8778\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 32s 218ms/step - loss: 0.2517 - accuracy: 0.8825\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2434 - accuracy: 0.8849\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 33s 219ms/step - loss: 0.2360 - accuracy: 0.8916\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2467 - accuracy: 0.8957\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.2365 - accuracy: 0.9175\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2287 - accuracy: 0.8906\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.2286 - accuracy: 0.8960\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.2404 - accuracy: 0.9021\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2248 - accuracy: 0.9068\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2215 - accuracy: 0.9283\n",
            "75/75 [==============================] - 6s 83ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.4490 - accuracy: 0.8593\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.4127 - accuracy: 0.8633\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.3686 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.3646 - accuracy: 0.8670\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 31s 208ms/step - loss: 0.3136 - accuracy: 0.8650\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.2922 - accuracy: 0.8667\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 31s 209ms/step - loss: 0.2787 - accuracy: 0.8694\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.2775 - accuracy: 0.8765\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 31s 209ms/step - loss: 0.2675 - accuracy: 0.8846\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.2631 - accuracy: 0.8990\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.2556 - accuracy: 0.9084\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.2519 - accuracy: 0.8667\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 31s 209ms/step - loss: 0.2448 - accuracy: 0.8734\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 31s 209ms/step - loss: 0.2281 - accuracy: 0.8738\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2335 - accuracy: 0.8765\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2308 - accuracy: 0.8775\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2306 - accuracy: 0.8788\n",
            "Epoch 00017: early stopping\n",
            "75/75 [==============================] - 6s 81ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.4347 - accuracy: 0.8674\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.3590 - accuracy: 0.8731\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.3431 - accuracy: 0.8731\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 32s 218ms/step - loss: 0.3176 - accuracy: 0.8738\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2993 - accuracy: 0.8745\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 32s 216ms/step - loss: 0.2889 - accuracy: 0.8762\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2794 - accuracy: 0.8775\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 33s 221ms/step - loss: 0.2605 - accuracy: 0.8792\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.2589 - accuracy: 0.8816\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 32s 211ms/step - loss: 0.2503 - accuracy: 0.8836\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.2584 - accuracy: 0.8859\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2434 - accuracy: 0.8856\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 32s 215ms/step - loss: 0.2292 - accuracy: 0.8906\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.2378 - accuracy: 0.8910\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 32s 214ms/step - loss: 0.2411 - accuracy: 0.8947\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 31s 211ms/step - loss: 0.2289 - accuracy: 0.9014\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2199 - accuracy: 0.9048\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 32s 212ms/step - loss: 0.2267 - accuracy: 0.9085\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 32s 213ms/step - loss: 0.2177 - accuracy: 0.9250\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 31s 210ms/step - loss: 0.2317 - accuracy: 0.9334\n",
            "75/75 [==============================] - 6s 81ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 8s 55ms/step - loss: 0.6201 - accuracy: 0.8640\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.5080 - accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.4415 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4105 - accuracy: 0.8644\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3987 - accuracy: 0.8644\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3940 - accuracy: 0.8644\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3915 - accuracy: 0.8644\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 8s 54ms/step - loss: 0.3899 - accuracy: 0.8644\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 8s 54ms/step - loss: 0.3878 - accuracy: 0.8644\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3857 - accuracy: 0.8644\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3836 - accuracy: 0.8644\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3809 - accuracy: 0.8644\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.3774 - accuracy: 0.8644\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3737 - accuracy: 0.8644\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3694 - accuracy: 0.8644\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3644 - accuracy: 0.8644\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3585 - accuracy: 0.8644\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3517 - accuracy: 0.8644\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3438 - accuracy: 0.8644\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3351 - accuracy: 0.8644\n",
            "75/75 [==============================] - 1s 13ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.6237 - accuracy: 0.8593\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.5133 - accuracy: 0.8627\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 8s 54ms/step - loss: 0.4468 - accuracy: 0.8627\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 8s 55ms/step - loss: 0.4148 - accuracy: 0.8627\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.4027 - accuracy: 0.8627\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 8s 50ms/step - loss: 0.3976 - accuracy: 0.8627\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3954 - accuracy: 0.8627\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3936 - accuracy: 0.8627\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3918 - accuracy: 0.8627\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3897 - accuracy: 0.8627\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 8s 56ms/step - loss: 0.3875 - accuracy: 0.8627\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 8s 54ms/step - loss: 0.3847 - accuracy: 0.8627\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3816 - accuracy: 0.8627\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3776 - accuracy: 0.8627\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3733 - accuracy: 0.8627\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3679 - accuracy: 0.8627\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3619 - accuracy: 0.8627\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3548 - accuracy: 0.8627\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 8s 55ms/step - loss: 0.3465 - accuracy: 0.8627\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3371 - accuracy: 0.8627\n",
            "75/75 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.6190 - accuracy: 0.8694\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.5010 - accuracy: 0.8731\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.4299 - accuracy: 0.8731\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.3967 - accuracy: 0.8731\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3840 - accuracy: 0.8731\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 8s 54ms/step - loss: 0.3790 - accuracy: 0.8731\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.3769 - accuracy: 0.8731\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3751 - accuracy: 0.8731\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3738 - accuracy: 0.8731\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3720 - accuracy: 0.8731\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 8s 50ms/step - loss: 0.3700 - accuracy: 0.8731\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3680 - accuracy: 0.8731\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.3655 - accuracy: 0.8731\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 8s 55ms/step - loss: 0.3625 - accuracy: 0.8731\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.3587 - accuracy: 0.8731\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.3552 - accuracy: 0.8731\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3501 - accuracy: 0.8731\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3446 - accuracy: 0.8731\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3385 - accuracy: 0.8731\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.3311 - accuracy: 0.8731\n",
            "75/75 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.5750 - accuracy: 0.8933\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.3620 - accuracy: 0.9286\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.2283 - accuracy: 0.9431\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.1736 - accuracy: 0.9552\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.1436 - accuracy: 0.9616\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.1248 - accuracy: 0.9636\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1101 - accuracy: 0.9663\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1000 - accuracy: 0.9687\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0924 - accuracy: 0.9707\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0819 - accuracy: 0.9731\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0756 - accuracy: 0.9754\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0681 - accuracy: 0.9788\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0627 - accuracy: 0.9801\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0562 - accuracy: 0.9832\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0521 - accuracy: 0.9835\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0474 - accuracy: 0.9862\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0435 - accuracy: 0.9865\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0391 - accuracy: 0.9879\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0355 - accuracy: 0.9906\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0315 - accuracy: 0.9899\n",
            "75/75 [==============================] - 0s 6ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.5704 - accuracy: 0.8936\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.3389 - accuracy: 0.9371\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2102 - accuracy: 0.9512\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1570 - accuracy: 0.9643\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1304 - accuracy: 0.9657\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1130 - accuracy: 0.9684\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0989 - accuracy: 0.9707\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0882 - accuracy: 0.9737\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0781 - accuracy: 0.9768\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0711 - accuracy: 0.9788\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0654 - accuracy: 0.9801\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.0593 - accuracy: 0.9835\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0548 - accuracy: 0.9852\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0496 - accuracy: 0.9872\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0473 - accuracy: 0.9879\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0440 - accuracy: 0.9892\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0419 - accuracy: 0.9886\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0386 - accuracy: 0.9902\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0368 - accuracy: 0.9906\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0337 - accuracy: 0.9916\n",
            "75/75 [==============================] - 0s 5ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.5457 - accuracy: 0.9048\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.3276 - accuracy: 0.9310\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2177 - accuracy: 0.9431\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1678 - accuracy: 0.9552\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1442 - accuracy: 0.9613\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1281 - accuracy: 0.9640\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1166 - accuracy: 0.9653\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.1055 - accuracy: 0.9680\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0970 - accuracy: 0.9707\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0887 - accuracy: 0.9707\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0814 - accuracy: 0.9731\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0754 - accuracy: 0.9744\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0688 - accuracy: 0.9771\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0639 - accuracy: 0.9785\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0592 - accuracy: 0.9808\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0555 - accuracy: 0.9812\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0505 - accuracy: 0.9842\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0463 - accuracy: 0.9852\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.0412 - accuracy: 0.9869\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0389 - accuracy: 0.9882\n",
            "75/75 [==============================] - 1s 7ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.4364 - accuracy: 0.8445\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3996 - accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.3971 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3883 - accuracy: 0.8644\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8644\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3796 - accuracy: 0.8644\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3715 - accuracy: 0.8644\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8644\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3525 - accuracy: 0.8644\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3474 - accuracy: 0.8654\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3453 - accuracy: 0.8667\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3259 - accuracy: 0.8694\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8755\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2997 - accuracy: 0.8788\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2864 - accuracy: 0.8920\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2716 - accuracy: 0.9024\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2570 - accuracy: 0.9081\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.2456 - accuracy: 0.9148\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.2361 - accuracy: 0.9219\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9280\n",
            "75/75 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.7745\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.4063 - accuracy: 0.8627\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8627\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8627\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3970 - accuracy: 0.8627\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.3913 - accuracy: 0.8627\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8627\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3865 - accuracy: 0.8627\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3803 - accuracy: 0.8627\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3746 - accuracy: 0.8627\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3686 - accuracy: 0.8627\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.8627\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8627\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3501 - accuracy: 0.8627\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.8633\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3358 - accuracy: 0.8633\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3265 - accuracy: 0.8657\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3124 - accuracy: 0.8728\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2993 - accuracy: 0.8805\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2908 - accuracy: 0.8876\n",
            "75/75 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.4052 - accuracy: 0.8694\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3881 - accuracy: 0.8731\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3818 - accuracy: 0.8731\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3746 - accuracy: 0.8731\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3670 - accuracy: 0.8731\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3677 - accuracy: 0.8731\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3624 - accuracy: 0.8731\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3615 - accuracy: 0.8731\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3497 - accuracy: 0.8731\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3414 - accuracy: 0.8735\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8735\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3324 - accuracy: 0.8738\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8755\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8782\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3005 - accuracy: 0.8843\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2929 - accuracy: 0.8863\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.2781 - accuracy: 0.8970\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2666 - accuracy: 0.9055\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.9102\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2418 - accuracy: 0.9182\n",
            "75/75 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.5766 - accuracy: 0.9091\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.3991 - accuracy: 0.9408\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.2826 - accuracy: 0.9458\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.2159 - accuracy: 0.9536\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.1775 - accuracy: 0.9586\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.1548 - accuracy: 0.9603\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1381 - accuracy: 0.9620\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1267 - accuracy: 0.9636\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1172 - accuracy: 0.9643\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1109 - accuracy: 0.9653\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1018 - accuracy: 0.9677\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0955 - accuracy: 0.9694\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0898 - accuracy: 0.9700\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0852 - accuracy: 0.9707\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0801 - accuracy: 0.9737\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0764 - accuracy: 0.9741\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0728 - accuracy: 0.9768\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0671 - accuracy: 0.9771\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0638 - accuracy: 0.9798\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0616 - accuracy: 0.9812\n",
            "75/75 [==============================] - 0s 6ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.5971 - accuracy: 0.8620\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.4132 - accuracy: 0.9435\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.2911 - accuracy: 0.9485\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.2193 - accuracy: 0.9546\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1782 - accuracy: 0.9599\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1537 - accuracy: 0.9640\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1366 - accuracy: 0.9650\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1244 - accuracy: 0.9674\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1145 - accuracy: 0.9687\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1059 - accuracy: 0.9684\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1003 - accuracy: 0.9697\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0941 - accuracy: 0.9707\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0886 - accuracy: 0.9721\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0841 - accuracy: 0.9734\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0808 - accuracy: 0.9737\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0768 - accuracy: 0.9764\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0728 - accuracy: 0.9781\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0701 - accuracy: 0.9781\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0672 - accuracy: 0.9801\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.0658 - accuracy: 0.9815\n",
            "75/75 [==============================] - 1s 7ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.5884 - accuracy: 0.8920\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.4134 - accuracy: 0.9398\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2963 - accuracy: 0.9415\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.2265 - accuracy: 0.9489\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1854 - accuracy: 0.9542\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1619 - accuracy: 0.9590\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.1446 - accuracy: 0.9623\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1329 - accuracy: 0.9640\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1243 - accuracy: 0.9650\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1160 - accuracy: 0.9657\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1090 - accuracy: 0.9670\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.1032 - accuracy: 0.9670\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0985 - accuracy: 0.9684\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0939 - accuracy: 0.9680\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0882 - accuracy: 0.9711\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0851 - accuracy: 0.9724\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0801 - accuracy: 0.9731\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0777 - accuracy: 0.9758\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 2s 13ms/step - loss: 0.0732 - accuracy: 0.9758\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 2s 14ms/step - loss: 0.0697 - accuracy: 0.9754\n",
            "75/75 [==============================] - 0s 6ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 9s 59ms/step - loss: 0.5214 - accuracy: 0.8559\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 8s 54ms/step - loss: 0.5160 - accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.5396 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4863 - accuracy: 0.8644\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 9s 59ms/step - loss: 0.5057 - accuracy: 0.8644\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.4847 - accuracy: 0.8644\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.4806 - accuracy: 0.8644\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.4904 - accuracy: 0.8644\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 8s 50ms/step - loss: 0.4920 - accuracy: 0.8644\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.4699 - accuracy: 0.8644\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 8s 52ms/step - loss: 0.4701 - accuracy: 0.8644\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4815 - accuracy: 0.8644\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4955 - accuracy: 0.8644\n",
            "Epoch 00013: early stopping\n",
            "75/75 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.4928 - accuracy: 0.8583\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 7s 49ms/step - loss: 0.4817 - accuracy: 0.8627\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.4463 - accuracy: 0.8627\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.5296 - accuracy: 0.8627\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 8s 50ms/step - loss: 0.5196 - accuracy: 0.8627\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 7s 50ms/step - loss: 0.4801 - accuracy: 0.8627\n",
            "Epoch 00006: early stopping\n",
            "75/75 [==============================] - 1s 13ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4630 - accuracy: 0.8671\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4938 - accuracy: 0.8731\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4806 - accuracy: 0.8731\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.4410 - accuracy: 0.8731\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 8s 53ms/step - loss: 0.4605 - accuracy: 0.8731\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.5087 - accuracy: 0.8731\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 8s 51ms/step - loss: 0.4670 - accuracy: 0.8731\n",
            "Epoch 00007: early stopping\n",
            "75/75 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.9098\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.9512\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2784 - accuracy: 0.9522\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2073 - accuracy: 0.9573\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1697 - accuracy: 0.9596\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9620\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 0.9636\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9650\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9663\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9684\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9684\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9707\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0843 - accuracy: 0.9711\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0797 - accuracy: 0.9734\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0757 - accuracy: 0.9751\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9774\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9791\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 0.9795\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9815\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9815\n",
            "75/75 [==============================] - 0s 2ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.5991 - accuracy: 0.8667\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.4190 - accuracy: 0.9583\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2890 - accuracy: 0.9579\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9613\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1688 - accuracy: 0.9647\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1424 - accuracy: 0.9674\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9677\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1161 - accuracy: 0.9690\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9704\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9714\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9727\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9741\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0823 - accuracy: 0.9751\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.9754\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9778\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0720 - accuracy: 0.9791\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0693 - accuracy: 0.9798\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9805\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9812\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 0.9828\n",
            "75/75 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.9307\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.3706 - accuracy: 0.9515\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.2515 - accuracy: 0.9546\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.1916 - accuracy: 0.9579\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.1598 - accuracy: 0.9623\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.1418 - accuracy: 0.9633\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1286 - accuracy: 0.9647\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.9653\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9664\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9667\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9694\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0922 - accuracy: 0.9697\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9714\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0822 - accuracy: 0.9731\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9738\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0749 - accuracy: 0.9748\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0709 - accuracy: 0.9775\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0681 - accuracy: 0.9778\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0645 - accuracy: 0.9785\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 1s 6ms/step - loss: 0.0611 - accuracy: 0.9798\n",
            "75/75 [==============================] - 0s 3ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4999 - accuracy: 0.8394\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4894 - accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.5061 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.5120 - accuracy: 0.8644\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4910 - accuracy: 0.8644\n",
            "Epoch 00005: early stopping\n",
            "75/75 [==============================] - 0s 4ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.5121 - accuracy: 0.8570\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4968 - accuracy: 0.8627\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4677 - accuracy: 0.8627\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4724 - accuracy: 0.8627\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4831 - accuracy: 0.8627\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 0.4994 - accuracy: 0.8627\n",
            "Epoch 00006: early stopping\n",
            "75/75 [==============================] - 0s 4ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.4822 - accuracy: 0.8671\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.4627 - accuracy: 0.8731\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.5645 - accuracy: 0.8731\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.4740 - accuracy: 0.8731\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 2s 15ms/step - loss: 0.4879 - accuracy: 0.8731\n",
            "Epoch 00005: early stopping\n",
            "75/75 [==============================] - 0s 4ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 36s 244ms/step - loss: 0.4035 - accuracy: 0.8623\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.3891 - accuracy: 0.8644\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.3773 - accuracy: 0.8644\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 36s 244ms/step - loss: 0.3664 - accuracy: 0.8647\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.3426 - accuracy: 0.8684\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 35s 238ms/step - loss: 0.3295 - accuracy: 0.8751\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 36s 241ms/step - loss: 0.2964 - accuracy: 0.8913\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.2793 - accuracy: 0.9024\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 36s 243ms/step - loss: 0.2583 - accuracy: 0.9138\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2483 - accuracy: 0.9165\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 36s 242ms/step - loss: 0.2305 - accuracy: 0.9226\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 36s 241ms/step - loss: 0.2163 - accuracy: 0.9297\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2080 - accuracy: 0.9347\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 36s 242ms/step - loss: 0.1972 - accuracy: 0.9371\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.1955 - accuracy: 0.9391\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.1942 - accuracy: 0.9421\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 36s 242ms/step - loss: 0.1893 - accuracy: 0.9374\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 37s 246ms/step - loss: 0.1771 - accuracy: 0.9478\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 36s 241ms/step - loss: 0.1736 - accuracy: 0.9475\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.1722 - accuracy: 0.9505\n",
            "75/75 [==============================] - 7s 89ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 35s 234ms/step - loss: 0.4039 - accuracy: 0.8623\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 35s 238ms/step - loss: 0.3931 - accuracy: 0.8627\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 35s 235ms/step - loss: 0.3840 - accuracy: 0.8627\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.3690 - accuracy: 0.8627\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 35s 238ms/step - loss: 0.3522 - accuracy: 0.8664\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 35s 236ms/step - loss: 0.3281 - accuracy: 0.8738\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 35s 238ms/step - loss: 0.3093 - accuracy: 0.8859\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 35s 235ms/step - loss: 0.2825 - accuracy: 0.9014\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 36s 241ms/step - loss: 0.2583 - accuracy: 0.9108\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2445 - accuracy: 0.9185\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 35s 238ms/step - loss: 0.2276 - accuracy: 0.9266\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2158 - accuracy: 0.9310\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 35s 236ms/step - loss: 0.2019 - accuracy: 0.9354\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 37s 246ms/step - loss: 0.1980 - accuracy: 0.9374\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 35s 237ms/step - loss: 0.1933 - accuracy: 0.9394\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 36s 241ms/step - loss: 0.1886 - accuracy: 0.9445\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 36s 243ms/step - loss: 0.1790 - accuracy: 0.9458\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.1737 - accuracy: 0.9482\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.1664 - accuracy: 0.9509\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 36s 242ms/step - loss: 0.1759 - accuracy: 0.9468\n",
            "75/75 [==============================] - 7s 89ms/step\n",
            "Epoch 1/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.3886 - accuracy: 0.8728\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 37s 245ms/step - loss: 0.3756 - accuracy: 0.8731\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 36s 242ms/step - loss: 0.3611 - accuracy: 0.8731\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 36s 241ms/step - loss: 0.3534 - accuracy: 0.8731\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 36s 244ms/step - loss: 0.3442 - accuracy: 0.8731\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 36s 242ms/step - loss: 0.3217 - accuracy: 0.8795\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 36s 244ms/step - loss: 0.3028 - accuracy: 0.8890\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2832 - accuracy: 0.8987\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 36s 238ms/step - loss: 0.2680 - accuracy: 0.9071\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.2563 - accuracy: 0.9139\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2341 - accuracy: 0.9223\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 35s 237ms/step - loss: 0.2198 - accuracy: 0.9337\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.2195 - accuracy: 0.9320\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.1976 - accuracy: 0.9394\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 36s 243ms/step - loss: 0.1999 - accuracy: 0.9381\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 35s 238ms/step - loss: 0.1877 - accuracy: 0.9398\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.1852 - accuracy: 0.9438\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 36s 239ms/step - loss: 0.1785 - accuracy: 0.9445\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 36s 238ms/step - loss: 0.1843 - accuracy: 0.9465\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 36s 240ms/step - loss: 0.1748 - accuracy: 0.9468\n",
            "75/75 [==============================] - 7s 88ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 117.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "223/223 [==============================] - 4s 18ms/step - loss: 0.5243 - accuracy: 0.9096\n",
            "Epoch 2/20\n",
            "223/223 [==============================] - 4s 18ms/step - loss: 0.2649 - accuracy: 0.9408\n",
            "Epoch 3/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.1681 - accuracy: 0.9567\n",
            "Epoch 4/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.1328 - accuracy: 0.9646\n",
            "Epoch 5/20\n",
            "223/223 [==============================] - 4s 17ms/step - loss: 0.1160 - accuracy: 0.9657\n",
            "Epoch 6/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.1010 - accuracy: 0.9699\n",
            "Epoch 7/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.0899 - accuracy: 0.9720\n",
            "Epoch 8/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.0794 - accuracy: 0.9749\n",
            "Epoch 9/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.0734 - accuracy: 0.9767\n",
            "Epoch 10/20\n",
            "223/223 [==============================] - 4s 17ms/step - loss: 0.0654 - accuracy: 0.9812\n",
            "Epoch 11/20\n",
            "223/223 [==============================] - 4s 18ms/step - loss: 0.0602 - accuracy: 0.9825\n",
            "Epoch 12/20\n",
            "223/223 [==============================] - 4s 17ms/step - loss: 0.0547 - accuracy: 0.9845\n",
            "Epoch 13/20\n",
            "223/223 [==============================] - 4s 18ms/step - loss: 0.0496 - accuracy: 0.9854\n",
            "Epoch 14/20\n",
            "223/223 [==============================] - 4s 18ms/step - loss: 0.0441 - accuracy: 0.9872\n",
            "Epoch 15/20\n",
            "223/223 [==============================] - 4s 17ms/step - loss: 0.0412 - accuracy: 0.9883\n",
            "Epoch 16/20\n",
            "223/223 [==============================] - 4s 17ms/step - loss: 0.0386 - accuracy: 0.9890\n",
            "Epoch 17/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.0340 - accuracy: 0.9912\n",
            "Epoch 18/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.0310 - accuracy: 0.9906\n",
            "Epoch 19/20\n",
            "223/223 [==============================] - 4s 16ms/step - loss: 0.0276 - accuracy: 0.9930\n",
            "Epoch 20/20\n",
            "223/223 [==============================] - 4s 17ms/step - loss: 0.0258 - accuracy: 0.9928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAafbzGyaI7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "d553074e-3e70-4c5a-dfe3-f0bf2a11d820"
      },
      "source": [
        "print(best_model)\n",
        "best_model['red_neuronal'].model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "         steps=[('transformacion',\n",
            "                 CountVectorizer(analyzer='word', binary=False,\n",
            "                                 decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.0,\n",
            "                                 max_features=None, min_df=1,\n",
            "                                 ngram_range=(1, 1), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                 tokenizer=None, vocabulary=None)),\n",
            "                ('matriz', <__main__.toArray object at 0x7fd7d3c6a4e0>),\n",
            "                ('red_neuronal',\n",
            "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd7d3c6a908>)],\n",
            "         verbose=False)\n",
            "Model: \"Mi_Red\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Capa_Entrada (Dense)         multiple                  4583424   \n",
            "_________________________________________________________________\n",
            "Capa_Oculta_1 (Dense)        multiple                  51300     \n",
            "_________________________________________________________________\n",
            "Dropout_0.2 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "Capa_Salida (Dense)          multiple                  202       \n",
            "=================================================================\n",
            "Total params: 4,634,926\n",
            "Trainable params: 4,634,926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnL98Vxgw9iH",
        "colab_type": "text"
      },
      "source": [
        "### **5. Predicción**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvnS8yJia9mQ",
        "colab_type": "text"
      },
      "source": [
        "Comparemos los dos modelos, el que construimos con los valores dados, y el que encontramos a través de la entonación de hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVSgjosEwPQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "47de4000-d1b1-4405-fed5-e47185076860"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss: {:4f}\\nTest Accuracy: {:4f}'.format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 11ms/step - loss: 0.4170 - accuracy: 0.8628\n",
            "Test loss: 0.417023\n",
            "Test Accuracy: 0.862780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk5XMGvna8r2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "332a8a2e-4fe8-4b4a-9aef-f8d5b6deb873"
      },
      "source": [
        "print(model.predict(X_test))\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.argmax(axis=-1)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7786636  0.2213364 ]\n",
            " [0.77965355 0.22034648]\n",
            " [0.77917796 0.22082204]\n",
            " ...\n",
            " [0.777393   0.222607  ]\n",
            " [0.78088903 0.21911098]\n",
            " [0.77866    0.22133994]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gONfgkQ_gPtg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2224bea3-053d-46c3-b846-b58063ef41e3"
      },
      "source": [
        "print(best_model.predict(Xtext_test))\n",
        "y_pred_text = best_model.predict(Xtext_test)\n",
        "y_pred_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 0s 7ms/step\n",
            "[0 0 0 ... 0 0 0]\n",
            "56/56 [==============================] - 0s 7ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TO2b7qcxMJm",
        "colab_type": "text"
      },
      "source": [
        "### **6. Validación**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McYnKxeBbgvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "2284985d-2a5a-4320-9a89-52049eadf20c"
      },
      "source": [
        "Y_test = y_test.argmax(axis=-1)\n",
        "print('Reporte para el modelo construido')\n",
        "print(classification_report(Y_test, y_pred, target_names=y.columns))\n",
        "print('Reporte para el modelo entonado')\n",
        "print(classification_report(Y_test, y_pred_text, target_names=y.columns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reporte para el modelo construido\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93       962\n",
            "        spam       0.00      0.00      0.00       153\n",
            "\n",
            "    accuracy                           0.86      1115\n",
            "   macro avg       0.43      0.50      0.46      1115\n",
            "weighted avg       0.74      0.86      0.80      1115\n",
            "\n",
            "Reporte para el modelo entonado\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      1.00       962\n",
            "        spam       1.00      0.95      0.97       153\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       1.00      0.97      0.98      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_WnJ4m4bibI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "64a82b02-c23c-4197-f159-4e202042d411"
      },
      "source": [
        "import seaborn as sns; sns.set()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "mat = confusion_matrix(Y_test, y_pred_text)\n",
        "sns.heatmap(mat.T, square=True, annot=True, cmap='Blues',fmt='d', cbar=False,\n",
        "            xticklabels=y.columns,\n",
        "            yticklabels=y.columns)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(54.260000000000005, 0.5, 'predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ZwZBEpEKSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1d5b8d23-4f5f-4cd9-f030-51269cb3d311"
      },
      "source": [
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPjik19m94K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "30eabdd3-e32e-4143-bc83-9c9d17c54b09"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZzI0TEtoQKN",
        "colab_type": "text"
      },
      "source": [
        "## Taller\n",
        "## Segundo Problema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whCqblnhodDq",
        "colab_type": "text"
      },
      "source": [
        "Ante la gran demanda de noticias que se generan hoy en día, el servicio público de radio y televisión Británica BBC desea realizar un sistema que le permita clasificar diferentes noticias para mostrarlas en su página web. Para ello, le ha brindado las noticias previamente clasificadas en cinco categorías.\n",
        "\n",
        "Se propone como ejercicio:\n",
        "\n",
        "1. Realizar ***un clasificador utilizando un MLP*** para la solución de este problema.\n",
        "2. Realizar una tabla comparando los resultados de los modelos del taller 4 con los arrojados por el ***MLP***.\n"
      ]
    }
  ]
}